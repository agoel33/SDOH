{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add your folder path to sys.path\n",
    "folder_path = '../Vornoi/QA/'\n",
    "sys.path.append(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qa_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "saved_net = BertRegressor.load_from_checkpoint(\"/home/user/Vornoi/QA/vornoi/uh138i3k/checkpoints/epoch=14-step=5625.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_router(input):\n",
    "    #Router\n",
    "    #saved net is a bert model. tokenize input and run it through the model\n",
    "    input_ids = tokenizer.encode(input, return_tensors='pt').to(saved_net.device)\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(input_ids.device)\n",
    "    output = saved_net(input_ids, attention_mask)\n",
    "    print(output)\n",
    "    best_model = model_names[output.argmax()]\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-medium', use_fast = False)\n",
    "model_names = [\n",
    "    #XXS (1b order)\n",
    "    # 'microsoft/phi-1_5',\n",
    "    # 'Fredithefish/Guanaco-3B-Uncensored-v2',\n",
    "    # 'EleutherAI/pythia-1b',\n",
    "    # 'PY007/TinyLlama-1.1B-step-50K-105b',\n",
    "    # 'cerebras/btlm-3b-8k-base',\n",
    "    #XS (5b order)\n",
    "    # 'TheBloke/Llama-2-7B-Chat-GGML', #some random error\n",
    "    'TheBloke/Llama-2-7b-Chat-GPTQ', #1s per sentence\n",
    "    # 'TheBloke/Airoboros-L2-7B-2.2-GPTQ', #some random error, ignoring for now\n",
    "    'HyperbeeAI/Tulpar-7b-v0',\n",
    "    # 'Open-Orca/Mistral-7B-OpenOrca',\n",
    "    # 'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    # 'mistralai/Mistral-7B-v0.1',\n",
    "    # 'circulus/Llama-2-7b-orca-v1',\n",
    "    # 'tiiuae/falcon-7b-instruct', #takes too long\n",
    "    # 'meta-llama/Llama-2-7b-hf',\n",
    "    # \"stabilityai/StableBeluga-7B\",\n",
    "    # 'Lajonbot/tableBeluga-7B-instruct-pl-lora_unload',\n",
    "    # 'THUDM/chatglm2-6b',\n",
    "    'lmsys/vicuna-7b-v1.5',\n",
    "    # 'lmsys/vicuna-7b-v1.3',\n",
    "    # 'lmsys/vicuna-7b-v1.1',\n",
    "    # 'TheBloke/Zarablend-L2-7B-GPTQ',\n",
    "    #Small (10b order)\n",
    "    'TheBloke/Spicyboros-13B-2.2-GPTQ',\n",
    "    # 'TheBloke/openchat_v3.2_super-GPTQ', #also slow\n",
    "    'TheBloke/Airoboros-L2-13B-2.2-GPTQ',\n",
    "    # 'TheBloke/Pygmalion-2-13B-GPTQ', #Takes 7s per sentence\n",
    "    # 'PygmalionAI/mythalion-13b',\n",
    "    # 'lmsys/vicuna-13b-v1.5',\n",
    "    # 'lmsys/vicuna-13b-v1.3',\n",
    "    # 'lmsys/vicuna-13b-v1.1',\n",
    "    # 'meta-llama/Llama-2-13b-hf',\n",
    "    # 'AIDC-ai-business/Luban-13B',\n",
    "    # 'uukuguy/speechless-llama2-luban-orca-platypus-13b',\n",
    "    # 'yeontaek/llama-2-13B-ensemble-v5',\n",
    "    # 'TFLai/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch',\n",
    "    # 'garage-bAInd/Stable-Platypus2-13B',\n",
    "    # 'TheBloke/COTHuginn-4.5-19B-GPTQ', # 30 seconds per iteration\n",
    "    'TheBloke/Unholy-v1-10l-13B-GPTQ', #1s per iteration\n",
    "    'TheBloke/Nous-Hermes-13B-Code-GPTQ', #2s per iteration\n",
    "    #Medium (30b order)\n",
    "    # 'garage-bAInd/GPlatty-30B',\n",
    "    # 'Writer/palmyra-20b-chat',\n",
    "    # 'upstage/llama-30b-instruct-2048',\n",
    "    # 'lmsys/vicuna-33b-v1.3',\n",
    "    # 'tiiuae/falcon-40b',\n",
    "    # 'garage-bAInd/SuperPlatty-30B',\n",
    "    # 'CalderaAI/30B-Lazarus',\n",
    "    'TheBloke/30B-Epsilon-GPTQ',\n",
    "    # 'TheBloke/Airoboros-33B-2.1-GPTQ', #some random error\n",
    "    #Large (70b order)\n",
    "    # 'meta-llama/Llama-2-70b-chat-hf',\n",
    "    # 'NousResearch/Nous-Hermes-Llama2-70b',\n",
    "    # 'garage-bAInd/Platypus2-70B-instruct',\n",
    "    # 'fangloveskari/Platypus_QLoRA_LLaMA_70b',\n",
    "    # 'upstage/SOLAR-0-70b-16bit',\n",
    "    # 'chargoddard/MelangeA-70b',\n",
    "    'TheBloke/Airoboros-65B-GPT4-m2.0-GPTQ',\n",
    "    'TheBloke/Llama-2-70B-Ensemble-v5-GPTQ', #3.5 seconds per iteration\n",
    "    'TheBloke/Uni-TianYan-70B-GPTQ', #3s per iteration\n",
    "    # # 'TheBloke/Synthia-70B-v1.2-GPTQ', #3s per example\n",
    "    'TheBloke/ORCA_LLaMA_70B_QLoRA-GPTQ', #3s per example\n",
    "    #XXL (150b order)\n",
    "    # 'TheBloke/Falcon-180B-Chat-GPTQ', # 60s per sample\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9858, 0.7499, 0.9585, 0.7836, 0.8507, 0.8484, 0.8536, 0.7936, 0.6699,\n",
      "         0.9375, 0.9661, 0.9637, 0.9725]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "name = run_router(\"The patient is homeless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = '''Below this prompt is a patient note. Does the note contain any evidence of homelessness? If it does contain evidence of homelessness return ABACRACADABRA \n",
    "along with direct evidence from the note, otherwise, return NONE with a justification of why there is no evidence of homelessness:\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= '''\n",
    "In the dimly lit corners of society, where shadows elongate and whispers of despair linger, there exists a stark reality that goes unnoticed by many—a reality that unfolds in the life of someone who is homeless. Picture a person, once firmly rooted in the comforting soil of stability, now adrift in the tumultuous sea of uncertainty. Each day, they navigate the harsh winds of life without the shelter of a permanent abode. The city streets, once bustling with purpose, now serve as both refuge and battleground for this individual.\n",
    "\n",
    "Amidst the towering structures of concrete and steel, this homeless soul seeks solace beneath the city's indifferent skyline. A tattered sleeping bag becomes their makeshift fortress, shielding them from the cold grip of the night. Hunger pangs echo through silent alleyways as the city sleeps, and the search for sustenance becomes a relentless quest. The distant hum of traffic, once background noise, now symbolizes the perpetual motion that seems to have left them behind.\n",
    "\n",
    "Yet, within the fragile shell of homelessness, resilience persists. There's a silent strength in the way this individual adapts to their ever-changing environment. Each possession, no matter how meager, becomes a cherished relic—a token of survival. A discarded cardboard box transforms into a humble abode, and the flickering glow of a streetlamp becomes a beacon of hope in the enveloping darkness.\n",
    "\n",
    "The journey of the homeless is not just a physical one; it is a profound exploration of the human spirit. Faces weathered by hardship tell stories of shattered dreams and unforeseen circumstances. The stigma that often shadows the homeless fails to capture the complexity of their narratives—the missed opportunities, the fractured relationships, and the societal structures that let them slip through the cracks.\n",
    "\n",
    "In the struggle for visibility, there exists an indomitable will to be seen, acknowledged, and understood. Despite the adversity, there is a shared humanity that transcends the labels imposed by circumstance. Every step taken on the unforgiving pavement is a testament to the endurance of the human spirit—a spirit that yearns for compassion, empathy, and the chance to rewrite the chapters of a life left unguarded.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] [CLS] below this prompt is a patient note. does the note contain any evidence of homelessness? if it does contain evidence of homelessness return abacracadabra along with direct evidence from the note, otherwise, return none with a justification of why there is no evidence of homelessness : in the dimly lit corners of society, where shadows elongate and whispers of despair linger, there exists a stark reality that goes unnoticed by many — a reality that unfolds in the life of someone who is homeless. picture a person, once firmly rooted in the comforting soil of stability, now adrift in the tumultuous sea of uncertainty. each day, they navigate the harsh winds of life without the shelter of a permanent abode. the city streets, once bustling with purpose, now serve as both refuge and battleground for this individual. amidst the towering structures of concrete and steel, this homeless soul seeks solace beneath the city's indifferent skyline. a tattered sleeping bag becomes their makeshift fortress, shielding them from the cold grip of the night. hunger pangs echo through silent alleyways as the city sleeps, and the search for sustenance becomes a relentless quest. the distant hum of traffic, once background noise, now symbolizes the perpetual motion that seems to have left them behind. yet, within the fragile shell of homelessness, resilience persists. there's a silent strength in the way this individual adapts to their ever - changing environment. each possession, no matter how meager, becomes a cherished relic — a token of survival. a discarded cardboard box transforms into a humble abode, and the flickering glow of a streetlamp becomes a beacon of hope in the enveloping darkness. the journey of the homeless is not just a physical one ; it is a profound exploration of the human spirit. faces weathered by hardship tell stories of shattered dreams and unforeseen circumstances. the stigma that often shadows the homeless fails to capture the complexity of their narratives — the missed opportunities, the fractured relationships, and the societal structures that let them slip through the cracks. in the struggle for visibility, there exists an indomitable will to be seen, acknowledged, and understood. despite the adversity, there is a shared humanity that transcends the labels imposed by circumstance. every step taken on the unforgiving pavement is a testament to the endurance of the human spirit — a spirit that yearns for compassion, empathy, and the chance to rewrite the chapters of a life left unguard [SEP]\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_prompt(text, prompt, tokenizer, num_tokens):\n",
    "    prompt_tokens = len(tokenizer.encode(prompt))\n",
    "    length = num_tokens - prompt_tokens\n",
    "    broken_text = []\n",
    "    if len(tokenizer.encode(text)) <= length:\n",
    "        broken_text.append(text)\n",
    "        return broken_text\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    tokenized_text= tokenizer.encode(text)\n",
    "    while len(tokenized_text[i*length: -1]) > length:\n",
    "        broken_text.append(tokenizer.decode(tokenized_text[i*length: (i+1)*length]))\n",
    "        i += 1\n",
    "    \n",
    "    broken_text.append(tokenizer.decode(tokenized_text[i*length: -1]))\n",
    "\n",
    "    broken_text[0] = broken_text[0][5:-1]\n",
    "    return broken_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'discharge_with_social_final.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working\n",
      "tensor([[0.9333, 0.4716, 0.7881, 0.5223, 0.6004, 0.5590, 0.5270, 0.4790, 0.3413,\n",
      "         0.5826, 0.8466, 0.8148, 0.8733]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "TheBloke/Llama-2-7b-Chat-GPTQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user/SDOH/test.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(name)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m classifier \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mtext-generation\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(name),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m                     device_map\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m output \u001b[39m=\u001b[39m classifier(sequence_to_classify)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:208\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, text_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    168\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(text_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/pipelines/base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1133\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1134\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/pipelines/base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1146\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1147\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1148\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1149\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/pipelines/base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1045\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1046\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1047\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1048\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:271\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m prefix_length\n\u001b[1;32m    270\u001b[0m \u001b[39m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m generated_sequence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49minput_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    272\u001b[0m out_b \u001b[39m=\u001b[39m generated_sequence\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/generation/utils.py:1673\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1656\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   1657\u001b[0m         input_ids,\n\u001b[1;32m   1658\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1670\u001b[0m     )\n\u001b[1;32m   1671\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1672\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1673\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1674\u001b[0m         input_ids,\n\u001b[1;32m   1675\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1676\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1677\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1678\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1679\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1680\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1681\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1682\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1683\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1684\u001b[0m     )\n\u001b[1;32m   1686\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1687\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/generation/utils.py:2521\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2518\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2520\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2521\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2522\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2523\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2524\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2525\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2526\u001b[0m )\n\u001b[1;32m   2528\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2529\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/accelerate/hooks.py:164\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1034\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1031\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1033\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1035\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1036\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1037\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1038\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1039\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1040\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1041\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1042\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1043\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1044\u001b[0m )\n\u001b[1;32m   1046\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1047\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpretraining_tp \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:922\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    912\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    913\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m         use_cache,\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    923\u001b[0m         hidden_states,\n\u001b[1;32m    924\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    925\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    926\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    927\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    928\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    929\u001b[0m     )\n\u001b[1;32m    931\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/accelerate/hooks.py:164\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:669\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    664\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing `padding_mask` is deprecated and will be removed in v4.37. Please make sure use `attention_mask` instead.`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m     )\n\u001b[1;32m    667\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m--> 669\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_layernorm(hidden_states)\n\u001b[1;32m    671\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[1;32m    672\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn(\n\u001b[1;32m    673\u001b[0m     hidden_states\u001b[39m=\u001b[39mhidden_states,\n\u001b[1;32m    674\u001b[0m     attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    680\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/accelerate/hooks.py:164\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:105\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    103\u001b[0m input_dtype \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    104\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m--> 105\u001b[0m variance \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39;49mpow(\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mmean(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, keepdim\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    106\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mrsqrt(variance \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariance_epsilon)\n\u001b[1;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m*\u001b[39m hidden_states\u001b[39m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_homeless = pd.DataFrame(columns=[\"Note\", \"Prompt\", \"Output\", \"Model\"])\n",
    "for i in range(1):\n",
    "  print(i)\n",
    "  entry = df.loc[i]['text']\n",
    "  sentences = sent_tokenize(entry)\n",
    "  for sentence in sentences:\n",
    "    print(\"working\")\n",
    "    truncated_sentences = truncate_prompt(sentence, prompt_1, tokenizer, 512)\n",
    "    for truncated_text in truncated_sentences:\n",
    "      sequence_to_classify = f\"NOTE {i} \" + prompt_1 + truncated_text\n",
    "      name = run_router(sequence_to_classify)\n",
    "      print(name)\n",
    "      classifier = pipeline(\"text-generation\", model= str(name),\n",
    "                          device_map= \"auto\")\n",
    "      output = classifier(sequence_to_classify)\n",
    "      print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
