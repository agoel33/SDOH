{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add your folder path to sys.path\n",
    "folder_path = '../Vornoi/QA/'\n",
    "sys.path.append(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qa_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "saved_net = BertRegressor.load_from_checkpoint(\"/home/user/Vornoi/QA/vornoi/uh138i3k/checkpoints/epoch=14-step=5625.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_router(input):\n",
    "    #Router\n",
    "    #saved net is a bert model. tokenize input and run it through the model\n",
    "    input_ids = tokenizer.encode(input, return_tensors='pt').to(saved_net.device)\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(input_ids.device)\n",
    "    output = saved_net(input_ids, attention_mask)\n",
    "    output = output[:, 1:]\n",
    "    print(output)\n",
    "    best_model = model_names[output.argmax()]\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-medium', use_fast = False)\n",
    "model_names = [\n",
    "    #XXS (1b order)\n",
    "    # 'microsoft/phi-1_5',\n",
    "    # 'Fredithefish/Guanaco-3B-Uncensored-v2',\n",
    "    # 'EleutherAI/pythia-1b',\n",
    "    # 'PY007/TinyLlama-1.1B-step-50K-105b',\n",
    "    # 'cerebras/btlm-3b-8k-base',\n",
    "    #XS (5b order)\n",
    "    # 'TheBloke/Llama-2-7B-Chat-GGML', #some random error\n",
    "    'TheBloke/Llama-2-7b-Chat-GPTQ', #1s per sentence\n",
    "    # 'TheBloke/Airoboros-L2-7B-2.2-GPTQ', #some random error, ignoring for now\n",
    "    'HyperbeeAI/Tulpar-7b-v0',\n",
    "    # 'Open-Orca/Mistral-7B-OpenOrca',\n",
    "    # 'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    # 'mistralai/Mistral-7B-v0.1',\n",
    "    # 'circulus/Llama-2-7b-orca-v1',\n",
    "    # 'tiiuae/falcon-7b-instruct', #takes too long\n",
    "    # 'meta-llama/Llama-2-7b-hf',\n",
    "    # \"stabilityai/StableBeluga-7B\",\n",
    "    # 'Lajonbot/tableBeluga-7B-instruct-pl-lora_unload',\n",
    "    # 'THUDM/chatglm2-6b',\n",
    "    'lmsys/vicuna-7b-v1.5',\n",
    "    # 'lmsys/vicuna-7b-v1.3',\n",
    "    # 'lmsys/vicuna-7b-v1.1',\n",
    "    # 'TheBloke/Zarablend-L2-7B-GPTQ',\n",
    "    #Small (10b order)\n",
    "    'TheBloke/Spicyboros-13B-2.2-GPTQ',\n",
    "    # 'TheBloke/openchat_v3.2_super-GPTQ', #also slow\n",
    "    'TheBloke/Airoboros-L2-13B-2.2-GPTQ',\n",
    "    # 'TheBloke/Pygmalion-2-13B-GPTQ', #Takes 7s per sentence\n",
    "    # 'PygmalionAI/mythalion-13b',\n",
    "    # 'lmsys/vicuna-13b-v1.5',\n",
    "    # 'lmsys/vicuna-13b-v1.3',\n",
    "    # 'lmsys/vicuna-13b-v1.1',\n",
    "    # 'meta-llama/Llama-2-13b-hf',\n",
    "    # 'AIDC-ai-business/Luban-13B',\n",
    "    # 'uukuguy/speechless-llama2-luban-orca-platypus-13b',\n",
    "    # 'yeontaek/llama-2-13B-ensemble-v5',\n",
    "    # 'TFLai/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch',\n",
    "    # 'garage-bAInd/Stable-Platypus2-13B',\n",
    "    # 'TheBloke/COTHuginn-4.5-19B-GPTQ', # 30 seconds per iteration\n",
    "    'TheBloke/Unholy-v1-10l-13B-GPTQ', #1s per iteration\n",
    "    'TheBloke/Nous-Hermes-13B-Code-GPTQ', #2s per iteration\n",
    "    #Medium (30b order)\n",
    "    # 'garage-bAInd/GPlatty-30B',\n",
    "    # 'Writer/palmyra-20b-chat',\n",
    "    # 'upstage/llama-30b-instruct-2048',\n",
    "    # 'lmsys/vicuna-33b-v1.3',\n",
    "    # 'tiiuae/falcon-40b',\n",
    "    # 'garage-bAInd/SuperPlatty-30B',\n",
    "    # 'CalderaAI/30B-Lazarus',\n",
    "    'TheBloke/30B-Epsilon-GPTQ',\n",
    "    # 'TheBloke/Airoboros-33B-2.1-GPTQ', #some random error\n",
    "    #Large (70b order)\n",
    "    # 'meta-llama/Llama-2-70b-chat-hf',\n",
    "    # 'NousResearch/Nous-Hermes-Llama2-70b',\n",
    "    # 'garage-bAInd/Platypus2-70B-instruct',\n",
    "    # 'fangloveskari/Platypus_QLoRA_LLaMA_70b',\n",
    "    # 'upstage/SOLAR-0-70b-16bit',\n",
    "    # 'chargoddard/MelangeA-70b',\n",
    "    'TheBloke/Airoboros-65B-GPT4-m2.0-GPTQ',\n",
    "    'TheBloke/Llama-2-70B-Ensemble-v5-GPTQ', #3.5 seconds per iteration\n",
    "    'TheBloke/Uni-TianYan-70B-GPTQ', #3s per iteration\n",
    "    # # 'TheBloke/Synthia-70B-v1.2-GPTQ', #3s per example\n",
    "    'TheBloke/ORCA_LLaMA_70B_QLoRA-GPTQ', #3s per example\n",
    "    #XXL (150b order)\n",
    "    # 'TheBloke/Falcon-180B-Chat-GPTQ', # 60s per sample\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = '''Below this prompt is a patient note. Does the note contain any evidence of homelessness? If it does contain evidence of homelessness return ABACRACADABRA \n",
    "along with direct evidence from the note, otherwise, return NONE with a justification of why there is no evidence of homelessness:\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= '''\n",
    "In the dimly lit corners of society, where shadows elongate and whispers of despair linger, there exists a stark reality that goes unnoticed by many—a reality that unfolds in the life of someone who is homeless. Picture a person, once firmly rooted in the comforting soil of stability, now adrift in the tumultuous sea of uncertainty. Each day, they navigate the harsh winds of life without the shelter of a permanent abode. The city streets, once bustling with purpose, now serve as both refuge and battleground for this individual.\n",
    "\n",
    "Amidst the towering structures of concrete and steel, this homeless soul seeks solace beneath the city's indifferent skyline. A tattered sleeping bag becomes their makeshift fortress, shielding them from the cold grip of the night. Hunger pangs echo through silent alleyways as the city sleeps, and the search for sustenance becomes a relentless quest. The distant hum of traffic, once background noise, now symbolizes the perpetual motion that seems to have left them behind.\n",
    "\n",
    "Yet, within the fragile shell of homelessness, resilience persists. There's a silent strength in the way this individual adapts to their ever-changing environment. Each possession, no matter how meager, becomes a cherished relic—a token of survival. A discarded cardboard box transforms into a humble abode, and the flickering glow of a streetlamp becomes a beacon of hope in the enveloping darkness.\n",
    "\n",
    "The journey of the homeless is not just a physical one; it is a profound exploration of the human spirit. Faces weathered by hardship tell stories of shattered dreams and unforeseen circumstances. The stigma that often shadows the homeless fails to capture the complexity of their narratives—the missed opportunities, the fractured relationships, and the societal structures that let them slip through the cracks.\n",
    "\n",
    "In the struggle for visibility, there exists an indomitable will to be seen, acknowledged, and understood. Despite the adversity, there is a shared humanity that transcends the labels imposed by circumstance. Every step taken on the unforgiving pavement is a testament to the endurance of the human spirit—a spirit that yearns for compassion, empathy, and the chance to rewrite the chapters of a life left unguarded.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_prompt(text, prompt, tokenizer, num_tokens):\n",
    "    prompt_tokens = len(tokenizer.encode(prompt))\n",
    "    length = num_tokens - prompt_tokens\n",
    "    broken_text = []\n",
    "    if len(tokenizer.encode(text)) <= length:\n",
    "        broken_text.append(text)\n",
    "        return broken_text\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    tokenized_text= tokenizer.encode(text)\n",
    "    while len(tokenized_text[i*length: -1]) > length:\n",
    "        broken_text.append(tokenizer.decode(tokenized_text[i*length: (i+1)*length]))\n",
    "        i += 1\n",
    "    \n",
    "    broken_text.append(tokenizer.decode(tokenized_text[i*length: -1]))\n",
    "\n",
    "    broken_text[0] = broken_text[0][5:-1]\n",
    "    return broken_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'discharge_with_social_final.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('text-generation', model = 'TheBloke/Llama-2-7b-Chat-GPTQ', device_map= \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_homeless = pd.DataFrame(columns=[\"Note\", \"Prompt\", \"Output\", \"Model\"])\n",
    "for i in range(1):\n",
    "  print(i)\n",
    "  entry = df.loc[i]['text']\n",
    "  sentences = sent_tokenize(entry)\n",
    "  for sentence in sentences:\n",
    "    print(\"working\")\n",
    "    truncated_sentences = truncate_prompt(sentence, prompt_1, tokenizer, 512)\n",
    "    for truncated_text in truncated_sentences:\n",
    "      sequence_to_classify = f\"NOTE {i} \" + prompt_1 + truncated_text\n",
    "      name = run_router(sequence_to_classify)\n",
    "      print(name)\n",
    "      output = classifier(sequence_to_classify)\n",
    "      print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "for i in range(50):\n",
    "  print(i)\n",
    "  entry = df.loc[i]['text']\n",
    "  sentences = sent_tokenize(entry)\n",
    "  for sentence in sentences:\n",
    "    truncated_sentences = truncate_prompt(sentence, prompt_1, tokenizer, 508)\n",
    "    for truncated_text in truncated_sentences:\n",
    "      sequence_to_classify = f\"NOTE {i} \" + prompt_1 + truncated_text\n",
    "      sequences.append(sequence_to_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "sequences_without_prompt = []\n",
    "for i in range(50):\n",
    "  print(i)\n",
    "  entry = df.loc[i]['text']\n",
    "  sentences = sent_tokenize(entry)\n",
    "  for sentence in sentences:\n",
    "    truncated_sentences = truncate_prompt(sentence, prompt_1, tokenizer, 508)\n",
    "    for truncated_text in truncated_sentences:\n",
    "      sequence_to_classify = f\"NOTE {i}\" + truncated_text\n",
    "      sequences_without_prompt.append(sequence_to_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model = 'TheBloke/Airoboros-L2-13B-2.2-GPTQ', device_map= \"auto\")\n",
    "candidate_label = [\"homeless\", \"not specified\", \"not homeless\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = classifier(sequences_without_prompt[:100], candidate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = []\n",
    "sequence_specific = []\n",
    "for i in range(len(output)):\n",
    "    sequence_specific.append(output[:][i]['sequence'])\n",
    "    order.append(output[:][i]['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Sequence': sequence_specific, str(model_names[1]): order}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>HyperbeeAI/Tulpar-7b-v0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOTE 0 \\nName:  ___                  Unit No: ...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOTE 0Chief Complaint:\\nalcohol intoxication\\n...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOTE 0Patient is noted to be a poor historian;...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOTE 0Of note, \\nshe reports active EtOH use a...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOTE 0She is unsure if she used other drugs/me...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NOTE 1- Treaters: Denies past or present outpa...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NOTE 1Per records, last had pending appointmen...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NOTE 1Currently states she\\ndoesn't remember l...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NOTE 1-Access to weapons: Denies\\n\\nPAST MEDIC...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NOTE 1- Hepatitis C\\n- H/o head injury (Per __...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sequence  \\\n",
       "0   NOTE 0 \\nName:  ___                  Unit No: ...   \n",
       "1   NOTE 0Chief Complaint:\\nalcohol intoxication\\n...   \n",
       "2   NOTE 0Patient is noted to be a poor historian;...   \n",
       "3   NOTE 0Of note, \\nshe reports active EtOH use a...   \n",
       "4   NOTE 0She is unsure if she used other drugs/me...   \n",
       "..                                                ...   \n",
       "95  NOTE 1- Treaters: Denies past or present outpa...   \n",
       "96  NOTE 1Per records, last had pending appointmen...   \n",
       "97  NOTE 1Currently states she\\ndoesn't remember l...   \n",
       "98  NOTE 1-Access to weapons: Denies\\n\\nPAST MEDIC...   \n",
       "99  NOTE 1- Hepatitis C\\n- H/o head injury (Per __...   \n",
       "\n",
       "                    HyperbeeAI/Tulpar-7b-v0  \n",
       "0   [not specified, not homeless, homeless]  \n",
       "1   [not specified, not homeless, homeless]  \n",
       "2   [not specified, not homeless, homeless]  \n",
       "3   [not specified, not homeless, homeless]  \n",
       "4   [not specified, not homeless, homeless]  \n",
       "..                                      ...  \n",
       "95  [not specified, not homeless, homeless]  \n",
       "96  [not specified, not homeless, homeless]  \n",
       "97  [not specified, not homeless, homeless]  \n",
       "98  [not specified, not homeless, homeless]  \n",
       "99  [not specified, not homeless, homeless]  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    }
   ],
   "source": [
    "for models in model_names[3:]:\n",
    "    classifier = pipeline(\"zero-shot-classification\", model = 'TheBloke/Airoboros-L2-13B-2.2-GPTQ', device_map= \"auto\")\n",
    "    candidate_label = [\"homeless\", \"not specified\", \"not homeless\"]\n",
    "    output = classifier(sequences_without_prompt[:100], candidate_label)\n",
    "    print(\"done\")\n",
    "    order = []\n",
    "    sequence_specific = []\n",
    "    for i in range(len(output)):\n",
    "        sequence_specific.append(output[:][i]['sequence'])\n",
    "        order.append(output[:][i]['labels'])\n",
    "    data = {'Sequence': sequence_specific, str(models): order}\n",
    "    df = pd.DataFrame(data)\n",
    "    big_df = big_df.merge(df)\n",
    "    print(\"dataframe\")\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>HyperbeeAI/Tulpar-7b-v0</th>\n",
       "      <th>TheBloke/Spicyboros-13B-2.2-GPTQ</th>\n",
       "      <th>TheBloke/Airoboros-L2-13B-2.2-GPTQ</th>\n",
       "      <th>TheBloke/Unholy-v1-10l-13B-GPTQ</th>\n",
       "      <th>TheBloke/Nous-Hermes-13B-Code-GPTQ</th>\n",
       "      <th>TheBloke/30B-Epsilon-GPTQ</th>\n",
       "      <th>TheBloke/Airoboros-65B-GPT4-m2.0-GPTQ</th>\n",
       "      <th>TheBloke/Llama-2-70B-Ensemble-v5-GPTQ</th>\n",
       "      <th>TheBloke/Uni-TianYan-70B-GPTQ</th>\n",
       "      <th>TheBloke/ORCA_LLaMA_70B_QLoRA-GPTQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOTE 0 \\nName:  ___                  Unit No: ...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOTE 0Chief Complaint:\\nalcohol intoxication\\n...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOTE 0Patient is noted to be a poor historian;...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOTE 0Of note, \\nshe reports active EtOH use a...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOTE 0She is unsure if she used other drugs/me...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>NOTE 1- Treaters: Denies past or present outpa...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>NOTE 1Per records, last had pending appointmen...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>NOTE 1Currently states she\\ndoesn't remember l...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>NOTE 1-Access to weapons: Denies\\n\\nPAST MEDIC...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>NOTE 1- Hepatitis C\\n- H/o head injury (Per __...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3166 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sequence  \\\n",
       "0     NOTE 0 \\nName:  ___                  Unit No: ...   \n",
       "1     NOTE 0Chief Complaint:\\nalcohol intoxication\\n...   \n",
       "2     NOTE 0Patient is noted to be a poor historian;...   \n",
       "3     NOTE 0Of note, \\nshe reports active EtOH use a...   \n",
       "4     NOTE 0She is unsure if she used other drugs/me...   \n",
       "...                                                 ...   \n",
       "3161  NOTE 1- Treaters: Denies past or present outpa...   \n",
       "3162  NOTE 1Per records, last had pending appointmen...   \n",
       "3163  NOTE 1Currently states she\\ndoesn't remember l...   \n",
       "3164  NOTE 1-Access to weapons: Denies\\n\\nPAST MEDIC...   \n",
       "3165  NOTE 1- Hepatitis C\\n- H/o head injury (Per __...   \n",
       "\n",
       "                      HyperbeeAI/Tulpar-7b-v0  \\\n",
       "0     [not specified, not homeless, homeless]   \n",
       "1     [not specified, not homeless, homeless]   \n",
       "2     [not specified, not homeless, homeless]   \n",
       "3     [not specified, not homeless, homeless]   \n",
       "4     [not specified, not homeless, homeless]   \n",
       "...                                       ...   \n",
       "3161  [not specified, not homeless, homeless]   \n",
       "3162  [not specified, not homeless, homeless]   \n",
       "3163  [not specified, not homeless, homeless]   \n",
       "3164  [not specified, not homeless, homeless]   \n",
       "3165  [not specified, not homeless, homeless]   \n",
       "\n",
       "             TheBloke/Spicyboros-13B-2.2-GPTQ  \\\n",
       "0     [homeless, not homeless, not specified]   \n",
       "1     [homeless, not homeless, not specified]   \n",
       "2     [not homeless, homeless, not specified]   \n",
       "3     [homeless, not homeless, not specified]   \n",
       "4     [not homeless, homeless, not specified]   \n",
       "...                                       ...   \n",
       "3161  [not homeless, homeless, not specified]   \n",
       "3162  [homeless, not homeless, not specified]   \n",
       "3163  [not homeless, homeless, not specified]   \n",
       "3164  [homeless, not homeless, not specified]   \n",
       "3165  [homeless, not homeless, not specified]   \n",
       "\n",
       "           TheBloke/Airoboros-L2-13B-2.2-GPTQ  \\\n",
       "0     [not homeless, homeless, not specified]   \n",
       "1     [not homeless, homeless, not specified]   \n",
       "2     [not homeless, homeless, not specified]   \n",
       "3     [not homeless, homeless, not specified]   \n",
       "4     [not homeless, homeless, not specified]   \n",
       "...                                       ...   \n",
       "3161  [not homeless, homeless, not specified]   \n",
       "3162  [not homeless, homeless, not specified]   \n",
       "3163  [not homeless, homeless, not specified]   \n",
       "3164  [not homeless, homeless, not specified]   \n",
       "3165  [not homeless, homeless, not specified]   \n",
       "\n",
       "              TheBloke/Unholy-v1-10l-13B-GPTQ  \\\n",
       "0     [not homeless, not specified, homeless]   \n",
       "1     [not homeless, homeless, not specified]   \n",
       "2     [not homeless, not specified, homeless]   \n",
       "3     [not homeless, homeless, not specified]   \n",
       "4     [homeless, not homeless, not specified]   \n",
       "...                                       ...   \n",
       "3161  [homeless, not homeless, not specified]   \n",
       "3162  [not homeless, homeless, not specified]   \n",
       "3163  [not homeless, homeless, not specified]   \n",
       "3164  [not homeless, homeless, not specified]   \n",
       "3165  [not homeless, homeless, not specified]   \n",
       "\n",
       "           TheBloke/Nous-Hermes-13B-Code-GPTQ  \\\n",
       "0     [not homeless, not specified, homeless]   \n",
       "1     [not homeless, not specified, homeless]   \n",
       "2     [not homeless, not specified, homeless]   \n",
       "3     [not homeless, not specified, homeless]   \n",
       "4     [not homeless, not specified, homeless]   \n",
       "...                                       ...   \n",
       "3161  [not homeless, not specified, homeless]   \n",
       "3162  [not homeless, not specified, homeless]   \n",
       "3163  [not homeless, not specified, homeless]   \n",
       "3164  [not homeless, not specified, homeless]   \n",
       "3165  [not homeless, not specified, homeless]   \n",
       "\n",
       "                    TheBloke/30B-Epsilon-GPTQ  \\\n",
       "0     [homeless, not homeless, not specified]   \n",
       "1     [not homeless, homeless, not specified]   \n",
       "2     [not homeless, homeless, not specified]   \n",
       "3     [not homeless, homeless, not specified]   \n",
       "4     [not homeless, not specified, homeless]   \n",
       "...                                       ...   \n",
       "3161  [not homeless, homeless, not specified]   \n",
       "3162  [homeless, not homeless, not specified]   \n",
       "3163  [not homeless, homeless, not specified]   \n",
       "3164  [not homeless, homeless, not specified]   \n",
       "3165  [not homeless, homeless, not specified]   \n",
       "\n",
       "        TheBloke/Airoboros-65B-GPT4-m2.0-GPTQ  \\\n",
       "0     [not specified, homeless, not homeless]   \n",
       "1     [not homeless, not specified, homeless]   \n",
       "2     [not homeless, homeless, not specified]   \n",
       "3     [not specified, not homeless, homeless]   \n",
       "4     [not homeless, homeless, not specified]   \n",
       "...                                       ...   \n",
       "3161  [homeless, not homeless, not specified]   \n",
       "3162  [not specified, homeless, not homeless]   \n",
       "3163  [not homeless, homeless, not specified]   \n",
       "3164  [not homeless, not specified, homeless]   \n",
       "3165  [not homeless, not specified, homeless]   \n",
       "\n",
       "        TheBloke/Llama-2-70B-Ensemble-v5-GPTQ  \\\n",
       "0     [homeless, not specified, not homeless]   \n",
       "1     [homeless, not specified, not homeless]   \n",
       "2     [homeless, not specified, not homeless]   \n",
       "3     [homeless, not specified, not homeless]   \n",
       "4     [not specified, homeless, not homeless]   \n",
       "...                                       ...   \n",
       "3161  [homeless, not specified, not homeless]   \n",
       "3162  [homeless, not specified, not homeless]   \n",
       "3163  [homeless, not specified, not homeless]   \n",
       "3164  [homeless, not specified, not homeless]   \n",
       "3165  [homeless, not specified, not homeless]   \n",
       "\n",
       "                TheBloke/Uni-TianYan-70B-GPTQ  \\\n",
       "0     [not specified, not homeless, homeless]   \n",
       "1     [not specified, not homeless, homeless]   \n",
       "2     [not specified, not homeless, homeless]   \n",
       "3     [not specified, not homeless, homeless]   \n",
       "4     [not specified, not homeless, homeless]   \n",
       "...                                       ...   \n",
       "3161  [not specified, not homeless, homeless]   \n",
       "3162  [not specified, not homeless, homeless]   \n",
       "3163  [not specified, not homeless, homeless]   \n",
       "3164  [not specified, not homeless, homeless]   \n",
       "3165  [not specified, not homeless, homeless]   \n",
       "\n",
       "           TheBloke/ORCA_LLaMA_70B_QLoRA-GPTQ  \n",
       "0     [not specified, not homeless, homeless]  \n",
       "1     [not specified, not homeless, homeless]  \n",
       "2     [not specified, not homeless, homeless]  \n",
       "3     [not specified, not homeless, homeless]  \n",
       "4     [not specified, homeless, not homeless]  \n",
       "...                                       ...  \n",
       "3161  [not specified, not homeless, homeless]  \n",
       "3162  [not specified, not homeless, homeless]  \n",
       "3163  [not specified, not homeless, homeless]  \n",
       "3164  [not specified, not homeless, homeless]  \n",
       "3165  [not specified, not homeless, homeless]  \n",
       "\n",
       "[3166 rows x 11 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user/SDOH/test.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mSequence\u001b[39m\u001b[39m\"\u001b[39m: sequences, \u001b[39m\"\u001b[39m\u001b[39mOutput\u001b[39m\u001b[39m\"\u001b[39m: output}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Create a dataframe from the dictionary\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "data = {\"Sequence\": sequences[:2], \"Output\": output}\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "  print(i)\n",
    "  entry = df.loc[i]['text']\n",
    "  sentences = sent_tokenize(entry)\n",
    "  for sentence in sentences:\n",
    "    truncated_sentences = truncate_prompt(sentence, prompt_1, tokenizer, 508)\n",
    "    for truncated_text in truncated_sentences:\n",
    "      sequence_to_classify = f\"NOTE {i} \" + prompt_1 + truncated_text\n",
    "      name = run_router(sequence_to_classify)\n",
    "      data_to_add = {\"Note\": f\"Note {i}\", \"Prompt\": sequence_to_classify, \"Topic\": \"Homelessness\", \"Model\": name}\n",
    "      df_homeless = pd.concat([df_homeless, pd.DataFrame(data_to_add, index = [0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_homeless.to_json(\"df_homeless_herd_outputs.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
