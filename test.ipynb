{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add your folder path to sys.path\n",
    "folder_path = '../Vornoi/QA/'\n",
    "sys.path.append(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qa_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-medium', use_fast = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/user/Vornoi/QA/vornoi/uh138i3k/checkpoints/epoch=14-step=5625.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user/SDOH/test.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m saved_net \u001b[39m=\u001b[39m BertRegressor\u001b[39m.\u001b[39;49mload_from_checkpoint(\u001b[39m\"\u001b[39;49m\u001b[39m/home/user/Vornoi/QA/vornoi/uh138i3k/checkpoints/epoch=14-step=5625.ckpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1552\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[39m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1472\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1473\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1479\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[1;32m   1480\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1481\u001b[0m \u001b[39m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \n\u001b[1;32m   1551\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1552\u001b[0m     loaded \u001b[39m=\u001b[39m _load_from_checkpoint(\n\u001b[1;32m   1553\u001b[0m         \u001b[39mcls\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1554\u001b[0m         checkpoint_path,\n\u001b[1;32m   1555\u001b[0m         map_location,\n\u001b[1;32m   1556\u001b[0m         hparams_file,\n\u001b[1;32m   1557\u001b[0m         strict,\n\u001b[1;32m   1558\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1559\u001b[0m     )\n\u001b[1;32m   1560\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:61\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m map_location \u001b[39m=\u001b[39m map_location \u001b[39mor\u001b[39;00m _default_map_location\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 61\u001b[0m     checkpoint \u001b[39m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[39m=\u001b[39;49mmap_location)\n\u001b[1;32m     63\u001b[0m \u001b[39m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     64\u001b[0m checkpoint \u001b[39m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     65\u001b[0m     checkpoint, checkpoint_path\u001b[39m=\u001b[39m(checkpoint_path \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(checkpoint_path, (\u001b[39mstr\u001b[39m, Path)) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     66\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/lightning_fabric/utilities/cloud_io.py:54\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     50\u001b[0m         \u001b[39mstr\u001b[39m(path_or_url),\n\u001b[1;32m     51\u001b[0m         map_location\u001b[39m=\u001b[39mmap_location,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     53\u001b[0m fs \u001b[39m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 54\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39;49mopen(path_or_url, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mload(f, map_location\u001b[39m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/fsspec/spec.py:1307\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> 1307\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[1;32m   1308\u001b[0m         path,\n\u001b[1;32m   1309\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   1310\u001b[0m         block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m   1311\u001b[0m         autocommit\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m   1312\u001b[0m         cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   1313\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1314\u001b[0m     )\n\u001b[1;32m   1315\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/fsspec/implementations/local.py:180\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 180\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/fsspec/implementations/local.py:302\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    301\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open()\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/site-packages/fsspec/implementations/local.py:307\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[1;32m    306\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[0;32m--> 307\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    308\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[1;32m    309\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/user/Vornoi/QA/vornoi/uh138i3k/checkpoints/epoch=14-step=5625.ckpt'"
     ]
    }
   ],
   "source": [
    "saved_net = BertRegressor.load_from_checkpoint(\"/home/user/SDOH/epoch=14-step=5625.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_router(input):\n",
    "    #Router\n",
    "    #saved net is a bert model. tokenize input and run it through the model\n",
    "    input_ids = tokenizer.encode(input, return_tensors='pt').to(saved_net.device)\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(input_ids.device)\n",
    "    output = saved_net(input_ids, attention_mask)\n",
    "    output = output[:, 1:]\n",
    "    print(output)\n",
    "    best_model = model_names[output.argmax()]\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-medium', use_fast = False)\n",
    "model_names = [\n",
    "    #XXS (1b order)\n",
    "    # 'microsoft/phi-1_5',\n",
    "    # 'Fredithefish/Guanaco-3B-Uncensored-v2',\n",
    "    # 'EleutherAI/pythia-1b',\n",
    "    # 'PY007/TinyLlama-1.1B-step-50K-105b',\n",
    "    # 'cerebras/btlm-3b-8k-base',\n",
    "    #XS (5b order)\n",
    "    # 'TheBloke/Llama-2-7B-Chat-GGML', #some random error\n",
    "    'TheBloke/Llama-2-7b-Chat-GPTQ', #1s per sentence\n",
    "    # 'TheBloke/Airoboros-L2-7B-2.2-GPTQ', #some random error, ignoring for now\n",
    "    'HyperbeeAI/Tulpar-7b-v0',\n",
    "    # 'Open-Orca/Mistral-7B-OpenOrca',\n",
    "    # 'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    # 'mistralai/Mistral-7B-v0.1',\n",
    "    # 'circulus/Llama-2-7b-orca-v1',\n",
    "    # 'tiiuae/falcon-7b-instruct', #takes too long\n",
    "    # 'meta-llama/Llama-2-7b-hf',\n",
    "    # \"stabilityai/StableBeluga-7B\",\n",
    "    # 'Lajonbot/tableBeluga-7B-instruct-pl-lora_unload',\n",
    "    # 'THUDM/chatglm2-6b',\n",
    "    'lmsys/vicuna-7b-v1.5',\n",
    "    # 'lmsys/vicuna-7b-v1.3',\n",
    "    # 'lmsys/vicuna-7b-v1.1',\n",
    "    # 'TheBloke/Zarablend-L2-7B-GPTQ',\n",
    "    #Small (10b order)\n",
    "    'TheBloke/Spicyboros-13B-2.2-GPTQ',\n",
    "    # 'TheBloke/openchat_v3.2_super-GPTQ', #also slow\n",
    "    'TheBloke/Airoboros-L2-13B-2.2-GPTQ',\n",
    "    # 'TheBloke/Pygmalion-2-13B-GPTQ', #Takes 7s per sentence\n",
    "    # 'PygmalionAI/mythalion-13b',\n",
    "    # 'lmsys/vicuna-13b-v1.5',\n",
    "    # 'lmsys/vicuna-13b-v1.3',\n",
    "    # 'lmsys/vicuna-13b-v1.1',\n",
    "    # 'meta-llama/Llama-2-13b-hf',\n",
    "    # 'AIDC-ai-business/Luban-13B',\n",
    "    # 'uukuguy/speechless-llama2-luban-orca-platypus-13b',\n",
    "    # 'yeontaek/llama-2-13B-ensemble-v5',\n",
    "    # 'TFLai/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch',\n",
    "    # 'garage-bAInd/Stable-Platypus2-13B',\n",
    "    # 'TheBloke/COTHuginn-4.5-19B-GPTQ', # 30 seconds per iteration\n",
    "    'TheBloke/Unholy-v1-10l-13B-GPTQ', #1s per iteration\n",
    "    'TheBloke/Nous-Hermes-13B-Code-GPTQ', #2s per iteration\n",
    "    #Medium (30b order)\n",
    "    # 'garage-bAInd/GPlatty-30B',\n",
    "    # 'Writer/palmyra-20b-chat',\n",
    "    # 'upstage/llama-30b-instruct-2048',\n",
    "    # 'lmsys/vicuna-33b-v1.3',\n",
    "    # 'tiiuae/falcon-40b',\n",
    "    # 'garage-bAInd/SuperPlatty-30B',\n",
    "    # 'CalderaAI/30B-Lazarus',\n",
    "    'TheBloke/30B-Epsilon-GPTQ',\n",
    "    # 'TheBloke/Airoboros-33B-2.1-GPTQ', #some random error\n",
    "    #Large (70b order)\n",
    "    # 'meta-llama/Llama-2-70b-chat-hf',\n",
    "    # 'NousResearch/Nous-Hermes-Llama2-70b',\n",
    "    # 'garage-bAInd/Platypus2-70B-instruct',\n",
    "    # 'fangloveskari/Platypus_QLoRA_LLaMA_70b',\n",
    "    # 'upstage/SOLAR-0-70b-16bit',\n",
    "    # 'chargoddard/MelangeA-70b',\n",
    "    'TheBloke/Airoboros-65B-GPT4-m2.0-GPTQ',\n",
    "    'TheBloke/Llama-2-70B-Ensemble-v5-GPTQ', #3.5 seconds per iteration\n",
    "    'TheBloke/Uni-TianYan-70B-GPTQ', #3s per iteration\n",
    "    # # 'TheBloke/Synthia-70B-v1.2-GPTQ', #3s per example\n",
    "    'TheBloke/ORCA_LLaMA_70B_QLoRA-GPTQ', #3s per example\n",
    "    #XXL (150b order)\n",
    "    # 'TheBloke/Falcon-180B-Chat-GPTQ', # 60s per sample\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = '''Below this prompt is a patient note. Does the note contain any evidence of homelessness? If it does contain evidence of homelessness return ABACRACADABRA \n",
    "along with direct evidence from the note, otherwise, return NONE with a justification of why there is no evidence of homelessness:\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= '''\n",
    "In the dimly lit corners of society, where shadows elongate and whispers of despair linger, there exists a stark reality that goes unnoticed by many—a reality that unfolds in the life of someone who is homeless. Picture a person, once firmly rooted in the comforting soil of stability, now adrift in the tumultuous sea of uncertainty. Each day, they navigate the harsh winds of life without the shelter of a permanent abode. The city streets, once bustling with purpose, now serve as both refuge and battleground for this individual.\n",
    "\n",
    "Amidst the towering structures of concrete and steel, this homeless soul seeks solace beneath the city's indifferent skyline. A tattered sleeping bag becomes their makeshift fortress, shielding them from the cold grip of the night. Hunger pangs echo through silent alleyways as the city sleeps, and the search for sustenance becomes a relentless quest. The distant hum of traffic, once background noise, now symbolizes the perpetual motion that seems to have left them behind.\n",
    "\n",
    "Yet, within the fragile shell of homelessness, resilience persists. There's a silent strength in the way this individual adapts to their ever-changing environment. Each possession, no matter how meager, becomes a cherished relic—a token of survival. A discarded cardboard box transforms into a humble abode, and the flickering glow of a streetlamp becomes a beacon of hope in the enveloping darkness.\n",
    "\n",
    "The journey of the homeless is not just a physical one; it is a profound exploration of the human spirit. Faces weathered by hardship tell stories of shattered dreams and unforeseen circumstances. The stigma that often shadows the homeless fails to capture the complexity of their narratives—the missed opportunities, the fractured relationships, and the societal structures that let them slip through the cracks.\n",
    "\n",
    "In the struggle for visibility, there exists an indomitable will to be seen, acknowledged, and understood. Despite the adversity, there is a shared humanity that transcends the labels imposed by circumstance. Every step taken on the unforgiving pavement is a testament to the endurance of the human spirit—a spirit that yearns for compassion, empathy, and the chance to rewrite the chapters of a life left unguarded.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_prompt(text, prompt, tokenizer, num_tokens):\n",
    "    prompt_tokens = len(tokenizer.encode(prompt))\n",
    "    length = num_tokens - prompt_tokens\n",
    "    broken_text = []\n",
    "    if len(tokenizer.encode(text)) <= length:\n",
    "        broken_text.append(text)\n",
    "        return broken_text\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    tokenized_text= tokenizer.encode(text)\n",
    "    while len(tokenized_text[i*length: -1]) > length:\n",
    "        broken_text.append(tokenizer.decode(tokenized_text[i*length: (i+1)*length]))\n",
    "        i += 1\n",
    "    \n",
    "    broken_text.append(tokenizer.decode(tokenized_text[i*length: -1]))\n",
    "\n",
    "    broken_text[0] = broken_text[0][5:-1]\n",
    "    return broken_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'discharge_with_social_final.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>note_type</th>\n",
       "      <th>note_seq</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002930-DS-12</td>\n",
       "      <td>10002930</td>\n",
       "      <td>25922998</td>\n",
       "      <td>DS</td>\n",
       "      <td>12</td>\n",
       "      <td>2198-04-22 00:00:00</td>\n",
       "      <td>2198-04-22 18:23:00</td>\n",
       "      <td>\\nName:  ___                  Unit No:   ___\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002930-DS-13</td>\n",
       "      <td>10002930</td>\n",
       "      <td>22733922</td>\n",
       "      <td>DS</td>\n",
       "      <td>13</td>\n",
       "      <td>2198-05-04 00:00:00</td>\n",
       "      <td>2198-05-04 19:18:00</td>\n",
       "      <td>\\nName:  ___                  Unit No:   ___\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003203-DS-19</td>\n",
       "      <td>10003203</td>\n",
       "      <td>25146997</td>\n",
       "      <td>DS</td>\n",
       "      <td>19</td>\n",
       "      <td>2153-04-29 00:00:00</td>\n",
       "      <td>2153-04-29 09:56:00</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10006825-DS-9</td>\n",
       "      <td>10006825</td>\n",
       "      <td>24767236</td>\n",
       "      <td>DS</td>\n",
       "      <td>9</td>\n",
       "      <td>2155-09-29 00:00:00</td>\n",
       "      <td>2155-09-29 14:20:00</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010399-DS-8</td>\n",
       "      <td>10010399</td>\n",
       "      <td>25356745</td>\n",
       "      <td>DS</td>\n",
       "      <td>8</td>\n",
       "      <td>2135-06-19 00:00:00</td>\n",
       "      <td>2135-06-18 07:07:00</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8922</th>\n",
       "      <td>19987975-DS-17</td>\n",
       "      <td>19987975</td>\n",
       "      <td>25543087</td>\n",
       "      <td>DS</td>\n",
       "      <td>17</td>\n",
       "      <td>2194-09-12 00:00:00</td>\n",
       "      <td>2194-09-13 06:55:00</td>\n",
       "      <td>\\nName:  ___                Unit No:   ___\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>19991773-DS-3</td>\n",
       "      <td>19991773</td>\n",
       "      <td>24714953</td>\n",
       "      <td>DS</td>\n",
       "      <td>3</td>\n",
       "      <td>2166-07-09 00:00:00</td>\n",
       "      <td>2166-07-09 17:51:00</td>\n",
       "      <td>\\nName:  ___               Unit No:   ___\\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>19992418-DS-19</td>\n",
       "      <td>19992418</td>\n",
       "      <td>20262597</td>\n",
       "      <td>DS</td>\n",
       "      <td>19</td>\n",
       "      <td>2145-01-16 00:00:00</td>\n",
       "      <td>2145-01-22 04:01:00</td>\n",
       "      <td>\\nName:  ___           Unit No:   ___\\n \\nAdm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>19993214-DS-9</td>\n",
       "      <td>19993214</td>\n",
       "      <td>28594508</td>\n",
       "      <td>DS</td>\n",
       "      <td>9</td>\n",
       "      <td>2168-04-24 00:00:00</td>\n",
       "      <td>2168-04-24 15:30:00</td>\n",
       "      <td>\\nName:  ___.              Unit No:   ___\\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>19995080-DS-13</td>\n",
       "      <td>19995080</td>\n",
       "      <td>23057109</td>\n",
       "      <td>DS</td>\n",
       "      <td>13</td>\n",
       "      <td>2147-07-18 00:00:00</td>\n",
       "      <td>2147-07-18 19:52:00</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8927 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             note_id  subject_id   hadm_id note_type  note_seq  \\\n",
       "0     10002930-DS-12    10002930  25922998        DS        12   \n",
       "1     10002930-DS-13    10002930  22733922        DS        13   \n",
       "2     10003203-DS-19    10003203  25146997        DS        19   \n",
       "3      10006825-DS-9    10006825  24767236        DS         9   \n",
       "4      10010399-DS-8    10010399  25356745        DS         8   \n",
       "...              ...         ...       ...       ...       ...   \n",
       "8922  19987975-DS-17    19987975  25543087        DS        17   \n",
       "8923   19991773-DS-3    19991773  24714953        DS         3   \n",
       "8924  19992418-DS-19    19992418  20262597        DS        19   \n",
       "8925   19993214-DS-9    19993214  28594508        DS         9   \n",
       "8926  19995080-DS-13    19995080  23057109        DS        13   \n",
       "\n",
       "                charttime            storetime  \\\n",
       "0     2198-04-22 00:00:00  2198-04-22 18:23:00   \n",
       "1     2198-05-04 00:00:00  2198-05-04 19:18:00   \n",
       "2     2153-04-29 00:00:00  2153-04-29 09:56:00   \n",
       "3     2155-09-29 00:00:00  2155-09-29 14:20:00   \n",
       "4     2135-06-19 00:00:00  2135-06-18 07:07:00   \n",
       "...                   ...                  ...   \n",
       "8922  2194-09-12 00:00:00  2194-09-13 06:55:00   \n",
       "8923  2166-07-09 00:00:00  2166-07-09 17:51:00   \n",
       "8924  2145-01-16 00:00:00  2145-01-22 04:01:00   \n",
       "8925  2168-04-24 00:00:00  2168-04-24 15:30:00   \n",
       "8926  2147-07-18 00:00:00  2147-07-18 19:52:00   \n",
       "\n",
       "                                                   text  \n",
       "0      \\nName:  ___                  Unit No:   ___\\...  \n",
       "1      \\nName:  ___                  Unit No:   ___\\...  \n",
       "2      \\nName:  ___                    Unit No:   __...  \n",
       "3      \\nName:  ___                    Unit No:   __...  \n",
       "4      \\nName:  ___                    Unit No:   __...  \n",
       "...                                                 ...  \n",
       "8922   \\nName:  ___                Unit No:   ___\\n ...  \n",
       "8923   \\nName:  ___               Unit No:   ___\\n \\...  \n",
       "8924   \\nName:  ___           Unit No:   ___\\n \\nAdm...  \n",
       "8925   \\nName:  ___.              Unit No:   ___\\n \\...  \n",
       "8926   \\nName:  ___                   Unit No:   ___...  \n",
       "\n",
       "[8927 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5377e95f972241f4a0984c2067a2a259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HyperbeeAI/Tulpar-7b-v0 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('zero-shot-classification', model = 'HyperbeeAI/Tulpar-7b-v0', device_map= 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "working\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'run_router' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user/SDOH/test.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m truncated_text \u001b[39min\u001b[39;00m truncated_sentences:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m   sequence_to_classify \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNOTE \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m prompt_1 \u001b[39m+\u001b[39m truncated_text\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m   name \u001b[39m=\u001b[39m run_router(sequence_to_classify)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m   \u001b[39mprint\u001b[39m(name)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m   output \u001b[39m=\u001b[39m classifier(sequence_to_classify)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_router' is not defined"
     ]
    }
   ],
   "source": [
    "df_homeless = pd.DataFrame(columns=[\"Note\", \"Prompt\", \"Output\", \"Model\"])\n",
    "for i in range(1):\n",
    "  print(i)\n",
    "  entry = df.loc[i]['text']\n",
    "  sentences = sent_tokenize(entry)\n",
    "  for sentence in sentences:\n",
    "    print(\"working\")\n",
    "    truncated_sentences = truncate_prompt(sentence, prompt_1, tokenizer, 512)\n",
    "    for truncated_text in truncated_sentences:\n",
    "      sequence_to_classify = f\"NOTE {i} \" + prompt_1 + truncated_text\n",
    "      name = run_router(sequence_to_classify)\n",
    "      print(name)\n",
    "      output = classifier(sequence_to_classify)\n",
    "      print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "for i in range(50):\n",
    "  print(i)\n",
    "  entry = df.loc[i]['text']\n",
    "  sentences = sent_tokenize(entry)\n",
    "  for sentence in sentences:\n",
    "    truncated_sentences = truncate_prompt(sentence, prompt_1, tokenizer, 508)\n",
    "    for truncated_text in truncated_sentences:\n",
    "      sequence_to_classify = f\"NOTE {i} \" + prompt_1 + truncated_text\n",
    "      sequences.append(sequence_to_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "sequences_without_prompt = []\n",
    "for i in range(50):\n",
    "  print(i)\n",
    "  entry = df.loc[i]['text']\n",
    "  sentences = sent_tokenize(entry)\n",
    "  for sentence in sentences:\n",
    "    truncated_sentences = truncate_prompt(sentence, prompt_1, tokenizer, 508)\n",
    "    for truncated_text in truncated_sentences:\n",
    "      sequence_to_classify = f\"NOTE {i}\" + \" \" + truncated_text\n",
    "      sequences_without_prompt.append(sequence_to_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Llama-2-7b-Chat-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model = 'TheBloke/Llama-2-7b-Chat-GPTQ', device_map= \"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_label = [\"homeless\", \"not specified\", \"not homeless\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5416"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences_without_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5212"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sequences_without_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = classifier(sequences_without_prompt[:10], candidate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = []\n",
    "sequence_specific = []\n",
    "for i in range(len(output)):\n",
    "    sequence_specific.append(output[:][i]['sequence'])\n",
    "    order.append(output[:][i]['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Sequence': sequence_specific, str(model_names[1]): order}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>HyperbeeAI/Tulpar-7b-v0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOTE 0  \\nName:  ___                  Unit No:...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOTE 0 Chief Complaint:\\nalcohol intoxication\\...</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOTE 0 Patient is noted to be a poor historian...</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOTE 0 Of note, \\nshe reports active EtOH use ...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOTE 0 She is unsure if she used other drugs/m...</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NOTE 0 In addition, she reports concern that s...</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NOTE 0 In \\naddition, patient reports active S...</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NOTE 0 In the ED, initial vitals: 98.2 88 150/...</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NOTE 0 During \\ntime in ED, patient became feb...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOTE 0 - Exam notable for: pleasant patient wi...</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sequence  \\\n",
       "0  NOTE 0  \\nName:  ___                  Unit No:...   \n",
       "1  NOTE 0 Chief Complaint:\\nalcohol intoxication\\...   \n",
       "2  NOTE 0 Patient is noted to be a poor historian...   \n",
       "3  NOTE 0 Of note, \\nshe reports active EtOH use ...   \n",
       "4  NOTE 0 She is unsure if she used other drugs/m...   \n",
       "5  NOTE 0 In addition, she reports concern that s...   \n",
       "6  NOTE 0 In \\naddition, patient reports active S...   \n",
       "7  NOTE 0 In the ED, initial vitals: 98.2 88 150/...   \n",
       "8  NOTE 0 During \\ntime in ED, patient became feb...   \n",
       "9  NOTE 0 - Exam notable for: pleasant patient wi...   \n",
       "\n",
       "                   HyperbeeAI/Tulpar-7b-v0  \n",
       "0  [not specified, not homeless, homeless]  \n",
       "1  [homeless, not homeless, not specified]  \n",
       "2  [homeless, not specified, not homeless]  \n",
       "3  [not specified, not homeless, homeless]  \n",
       "4  [homeless, not homeless, not specified]  \n",
       "5  [homeless, not specified, not homeless]  \n",
       "6  [homeless, not specified, not homeless]  \n",
       "7  [not specified, homeless, not homeless]  \n",
       "8  [not specified, not homeless, homeless]  \n",
       "9  [homeless, not specified, not homeless]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.drop_duplicates(subset = 'Sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperbeeAI/Tulpar-7b-v0\n"
     ]
    }
   ],
   "source": [
    "for models in model_names[1:2]:\n",
    "    print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7308212b5b4129a84ad0d23776bb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HyperbeeAI/Tulpar-7b-v0 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Tokenizer was not supporting padding necessary for zero-shot, attempting to use  `pad_token=eos_token`\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6287de5199cc4266990c15f220b5ba19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at lmsys/vicuna-7b-v1.5 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Spicyboros-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Airoboros-L2-13B-2.2-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Unholy-v1-10l-13B-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at TheBloke/Nous-Hermes-13B-Code-GPTQ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for models in model_names[1:]:\n",
    "    classifier = pipeline(\"zero-shot-classification\", model = models, device_map= \"auto\")\n",
    "    candidate_label = [\"homeless\", \"not specified\", \"not homeless\"]\n",
    "    output = classifier(sequences_without_prompt[:], candidate_label)\n",
    "    print(\"done\")\n",
    "    order = []\n",
    "    sequence_specific = []\n",
    "    for i in range(len(output)):\n",
    "        sequence_specific.append(output[:][i]['sequence'])\n",
    "        order.append(output[:][i]['labels'])\n",
    "    data = {'Sequence': sequence_specific, str(models): order}\n",
    "    df = pd.DataFrame(data)\n",
    "    big_df = big_df.merge(df)\n",
    "    print(\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = big_df.drop_duplicates(subset='Sequence').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>TheBloke/Llama-2-7b-Chat-GPTQ</th>\n",
       "      <th>HyperbeeAI/Tulpar-7b-v0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NOTE 0  \\nName:  ___                  Unit No:...</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NOTE 0 Chief Complaint:\\nalcohol intoxication\\...</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NOTE 0 Patient is noted to be a poor historian...</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not homeless, homeless, not specified]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NOTE 0 Of note, \\nshe reports active EtOH use ...</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NOTE 0 She is unsure if she used other drugs/m...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>7291</td>\n",
       "      <td>NOTE 49 Please continue all medications as dir...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208</th>\n",
       "      <td>7292</td>\n",
       "      <td>NOTE 49 Please avoid abusing alcohol and any d...</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "      <td>[homeless, not specified, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>7293</td>\n",
       "      <td>NOTE 49 Please contact your outpatient psychia...</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "      <td>[not specified, homeless, not homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>7294</td>\n",
       "      <td>NOTE 49 Please call ___ or go to your nearest ...</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "      <td>[not specified, not homeless, homeless]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>7295</td>\n",
       "      <td>NOTE 49 If you need to talk to a ___ Staff Mem...</td>\n",
       "      <td>[not homeless, not specified, homeless]</td>\n",
       "      <td>[homeless, not homeless, not specified]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5212 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                           Sequence  \\\n",
       "0         0  NOTE 0  \\nName:  ___                  Unit No:...   \n",
       "1         1  NOTE 0 Chief Complaint:\\nalcohol intoxication\\...   \n",
       "2         2  NOTE 0 Patient is noted to be a poor historian...   \n",
       "3         3  NOTE 0 Of note, \\nshe reports active EtOH use ...   \n",
       "4         4  NOTE 0 She is unsure if she used other drugs/m...   \n",
       "...     ...                                                ...   \n",
       "5207   7291  NOTE 49 Please continue all medications as dir...   \n",
       "5208   7292  NOTE 49 Please avoid abusing alcohol and any d...   \n",
       "5209   7293  NOTE 49 Please contact your outpatient psychia...   \n",
       "5210   7294  NOTE 49 Please call ___ or go to your nearest ...   \n",
       "5211   7295  NOTE 49 If you need to talk to a ___ Staff Mem...   \n",
       "\n",
       "                TheBloke/Llama-2-7b-Chat-GPTQ  \\\n",
       "0     [not specified, homeless, not homeless]   \n",
       "1     [not specified, homeless, not homeless]   \n",
       "2     [homeless, not homeless, not specified]   \n",
       "3     [not specified, homeless, not homeless]   \n",
       "4     [not specified, not homeless, homeless]   \n",
       "...                                       ...   \n",
       "5207  [not specified, not homeless, homeless]   \n",
       "5208  [not specified, homeless, not homeless]   \n",
       "5209  [not specified, not homeless, homeless]   \n",
       "5210  [homeless, not homeless, not specified]   \n",
       "5211  [not homeless, not specified, homeless]   \n",
       "\n",
       "                      HyperbeeAI/Tulpar-7b-v0  \n",
       "0     [not homeless, not specified, homeless]  \n",
       "1     [homeless, not specified, not homeless]  \n",
       "2     [not homeless, homeless, not specified]  \n",
       "3     [not specified, not homeless, homeless]  \n",
       "4     [homeless, not specified, not homeless]  \n",
       "...                                       ...  \n",
       "5207  [not specified, homeless, not homeless]  \n",
       "5208  [homeless, not specified, not homeless]  \n",
       "5209  [not specified, homeless, not homeless]  \n",
       "5210  [not specified, not homeless, homeless]  \n",
       "5211  [homeless, not homeless, not specified]  \n",
       "\n",
       "[5212 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user/SDOH/test.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mSequence\u001b[39m\u001b[39m\"\u001b[39m: sequences, \u001b[39m\"\u001b[39m\u001b[39mOutput\u001b[39m\u001b[39m\"\u001b[39m: output}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Create a dataframe from the dictionary\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvaldi/home/user/SDOH/test.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "data = {\"Sequence\": sequences[:2], \"Output\": output}\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "  print(i)\n",
    "  entry = df.loc[i]['text']\n",
    "  sentences = sent_tokenize(entry)\n",
    "  for sentence in sentences:\n",
    "    truncated_sentences = truncate_prompt(sentence, prompt_1, tokenizer, 508)\n",
    "    for truncated_text in truncated_sentences:\n",
    "      sequence_to_classify = f\"NOTE {i} \" + prompt_1 + truncated_text\n",
    "      name = run_router(sequence_to_classify)\n",
    "      data_to_add = {\"Note\": f\"Note {i}\", \"Prompt\": sequence_to_classify, \"Topic\": \"Homelessness\", \"Model\": name}\n",
    "      df_homeless = pd.concat([df_homeless, pd.DataFrame(data_to_add, index = [0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_homeless.to_json(\"df_homeless_herd_outputs.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
